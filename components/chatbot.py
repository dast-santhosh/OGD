import streamlit as st

import requests

import json

import os

from typing import Dict, List, Optional

# Corrected Imports: Use relative paths to access services and utils modules

from services.weather_service import WeatherService

from services.nasa_service import NASAService

from utils.data_utils import get_bengaluru_coordinates

# --- API Configuration & Environment Variables (Gemini API) ---

GEMINI_API_KEY = "AIzaSyBdmm58juT-4EL5Vc78sXhtqNZ8dsxvq8c"

GEMINI_MODEL = "gemini-2.0-flash"

GEMINI_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"



# Helper function to call the Gemini API using requests

def generate_ai_content(system_prompt: str, user_input: str) -> str:

Â  Â  """Helper function to call the Gemini API using requests."""

Â  Â  url = GEMINI_URL

Â  Â  model_name = GEMINI_MODEL

Â  Â  headers = {"Content-Type": "application/json"}

Â  Â  payload = {

Â  Â  Â  Â  "contents": [{"parts": [{"text": user_input}]}],

Â  Â  Â  Â  "systemInstruction": {"parts": [{"text": system_prompt}]}

Â  Â  }



Â  Â  try:

Â  Â  Â  Â  max_retries = 3

Â  Â  Â  Â  initial_delay = 1

Â  Â  Â  Â  for attempt in range(max_retries):

Â  Â  Â  Â  Â  Â  response = requests.post(url, headers=headers, json=payload, timeout=30)

Â  Â  Â  Â  Â  Â  if response.status_code == 200:

Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  if response.status_code in [429, 500, 503] and attempt < max_retries - 1:

Â  Â  Â  Â  Â  Â  Â  Â  import time

Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(initial_delay * (2 ** attempt))

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  response.raise_for_status()

Â  Â  Â  Â Â 

Â  Â  Â  Â  result = response.json()

Â  Â  Â  Â  candidate = result.get('candidates', [{}])[0]

Â  Â  Â  Â  if candidate and candidate.get('content') and candidate['content'].get('parts'):

Â  Â  Â  Â  Â  Â  return candidate['content']['parts'][0].get('text', "AI response text not found.")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  error_message = result.get('error', {}).get('message', 'Unknown API Error')

Â  Â  Â  Â  Â  Â  return f"The Gemini AI returned an error: {error_message}"



Â  Â  except requests.exceptions.RequestException as e:

Â  Â  Â  Â  return f"Sorry, I'm having trouble connecting to the Gemini AI service ({model_name}). Error details: {str(e)}"



# Main function to create and render the chatbot interface

def create_chatbot(stakeholder: str, env_data: Dict):

Â  Â  st.header("ðŸ¤– Terrabot - AI Climate Assistant")

Â  Â  st.markdown("*Ask me anything about Bengaluru's climate, air quality, water bodies, and urban environment!*")



Â  Â  # Stakeholder-specific chatbot context setup

Â  Â  context_prompts = {

Â  Â  Â  Â  "Citizens": "You are an environmental AI assistant helping citizens of Bengaluru. Provide clear, actionable advice about air quality, water safety, pollution, and health recommendations. Use simple language and focus on practical solutions.",

Â  Â  Â  Â  "BBMP (City Planning)": "You are an AI assistant for BBMP city planners in Bengaluru. Provide data-driven insights for urban planning...",

Â  Â  Â  Â  "BWSSB (Water Board)": "You are an AI assistant for BWSSB water management in Bengaluru...",

Â  Â  Â  Â  "BESCOM (Electricity)": "You are an AI assistant for BESCOM electricity management in Bengaluru...",

Â  Â  Â  Â  "Researchers": "You are an AI assistant for environmental researchers studying Bengaluru...",

Â  Â  Â  Â  "General": "You are a general environmental AI assistant for Bengaluru climate data..."

Â  Â  }

Â  Â  context_prompt = context_prompts.get(stakeholder, context_prompts["General"])

Â  Â  st.info(f"ðŸ’¬ **You are currently in the role of a {stakeholder}**. Ask me a question!")



Â  Â  if "messages" not in st.session_state:

Â  Â  Â  Â  st.session_state.messages = [

Â  Â  Â  Â  Â  Â  {"role": "assistant", "content": "Hello! I'm Terrabot, your AI climate assistant for Bengaluru. What would you like to know?"}

Â  Â  Â  Â  ]



Â  Â  for message in st.session_state.messages:

Â  Â  Â  Â  with st.chat_message(message["role"]):

Â  Â  Â  Â  Â  Â  st.markdown(message["content"])



Â  Â  if prompt := st.chat_input("Ask about Bengaluru's climate..."):

Â  Â  Â  Â  st.session_state.messages.append({"role": "user", "content": prompt})



Â  Â  Â  Â  with st.chat_message("user"):

Â  Â  Â  Â  Â  Â  st.markdown(prompt)



Â  Â  Â  Â  with st.chat_message("assistant"):

Â  Â  Â  Â  Â  Â  with st.spinner("Analyzing environmental data..."):

Â  Â  Â  Â  Â  Â  Â  Â  env_context = f"""

Â  Â  Â  Â  Â  Â  Â  Â  Current Bengaluru Environmental Data:

Â  Â  Â  Â  Â  Â  Â  Â  - Average Temperature: 32.5Â°C (above normal by 2.1Â°C)

Â  Â  Â  Â  Â  Â  Â  Â  - Air Quality Index: 156 (Unhealthy)

Â  Â  Â  Â  Â  Â  Â  Â  - Lake Health Index: 6.2/10 (declining)

Â  Â  Â  Â  Â  Â  Â  Â  """

Â  Â  Â  Â  Â  Â  Â  Â  full_system_prompt = context_prompt + "\n\n" + env_context

Â  Â  Â  Â  Â  Â  Â  Â  ai_response = generate_ai_content(full_system_prompt, prompt)

Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(ai_response)

Â  Â  Â  Â Â 

Â  Â  Â  Â  st.session_state.messages.append({"role": "assistant", "content": ai_response})



Â  Â  with st.expander("ðŸ“Š Available Environmental Data"):

Â  Â  Â  Â  st.markdown("""... (markdown content here) ...""")



Â  Â  if st.button("ðŸ—‘ï¸ Clear Chat History"):

Â  Â  Â  Â  st.session_state.messages = []

Â  Â  Â  Â  st.rerun()
